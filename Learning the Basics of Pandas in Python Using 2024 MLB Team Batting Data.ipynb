{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fb99814",
   "metadata": {},
   "source": [
    "Comments: M. Schuckers \n",
    "11 June 2025\n",
    "\n",
    "1. Add a set of learning goals at the start that are specifically what students should take away from the module - done\n",
    "2. 'pip install pandas' did not work for me - Still solving \n",
    "3. Add some motivation about why we would read in data. - done\n",
    "4. Motivate the use of 'NA' for EXCEL_Batting_Data_2024_NA_version, be clear about why we might want to do that. - done\n",
    "5. Add some additional detail about what is a Dataframe at the start of that section - done\n",
    "6. Explain what 0-based indexing is - done\n",
    "7. Add some depth to the np.nan section.  Explain a bit about missing data\n",
    "8. When you change to float and you're looking at Dtype's, maybe talk about the consequences of this difference\n",
    "9. Talk a bit about numpy and what it is useful for\n",
    "10. Make sure you've got comments for nearly all of your cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ececf15d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "Title: \"Learning the Basics of Pandas in Python Using 2024 MLB Team Batting Data\"\n",
    "\n",
    "Author:\n",
    "  - Name: Austin Hayes\n",
    "\n",
    "  -  Email: ahayes65@charlotte.edu\n",
    "\n",
    "  - Affiliation: University of North Carolina at Charlotte\n",
    "\n",
    "Date: June 2, 2025\n",
    "\n",
    "Description: Using 2024 Batting Data from every team, we will be exploring the basic functions and uses of the Pandas library in Python in order to learn about Data Science in Python.\n",
    "\n",
    "Categories:\n",
    "  - Dataframes\n",
    "  - Summary statistics\n",
    "  - Importing and Reading data\n",
    "  - Series\n",
    "  - Data Science\n",
    "\n",
    "\n",
    "### Data\n",
    "\n",
    "This Dataset is Originally from Baseball Reference and has been converted to CSV and Excel files for this learning module. \n",
    "\n",
    "Visit their website at: https://www.baseball-reference.com/leagues/majors/2024.shtml\n",
    "\n",
    "The data set contains 32 rows and 29 columns. Each row represents a MLB team.\n",
    "\n",
    "Download data: \n",
    "\n",
    "Available on the [Data For Pandas Module Data Repository](https://github.com/ahaze65/Data-For-Pandas-Module): [2024_MLB_Team_Batting_Data.csv](https://raw.githubusercontent.com/ahaze65/Data-For-Pandas-Module/refs/heads/main/2024_MLB_Team_Batting_Data.csv)\n",
    "\n",
    "<details>\n",
    "<summary><b>Variable Descriptions</b></summary>\n",
    "\n",
    "| Variable | Description |\n",
    "|----|----------------------------|\n",
    "| Tm | Team |\n",
    "| '#Bat' | Number of Players used in Games | \n",
    "| BatAge | Batters’ average age. Weighted by AB + Games Played |\n",
    "| R/G | Runs Scored Per Game |\n",
    "| G | Games Played or Pitched |\n",
    "| PA | Plate Appearances. When available, we use actual plate appearances from play-by-play game accounts. Otherwise estimated using AB + BB + HBP + SF + SH, which excludes catcher interferences. When this color, click for a summary of each PA. |\n",
    "| AB | At Bats |\n",
    "| R | Runs Scored/Allowed |\n",
    "| H | Hits/Hits Allowed |\n",
    "| 2B | Second Base Hits? Not stated on Website. | \n",
    "| 3B | Third Base Hits? Not stated on Website. |\n",
    "| HR | Home Runs Hit/Allowed |\n",
    "| RBI | Runs Batted In |\n",
    "| SB | Stolen Bases |\n",
    "| CS | Caught Stealing |\n",
    "| BB | Bases on Balls/Walks |\n",
    "| SO | Strikeouts |\n",
    "| BA | Hits/At Bats. For recent years, leaders need 3.1 PA per team game played. Bold indicates highest BA using current stats. Gold means awarded title at end of year.|\n",
    "| OBP | (H + BB + HBP) / (At Bats + BB + HBP + SF). For recent years, leaders need 3.1 PA per team game played. |\n",
    "|SLG | Total Bases/At Bats OR (1B + 2*2B + 3*3B + 4*HR) / AB. For recent years, leaders need 3.1 PA per team game played. |\n",
    "|OPS | On-Base + Slugging Percentages. For recent years, leaders need 3.1 PA per team game played. |\n",
    "|OPS+ | 100*[OBP/lg OBP + SLG/lg SLG - 1]. Adjusted to the player’s ballpark(s) |\n",
    "| TB | Total Bases. Singles + 2 x Doubles + 3 x Triples + 4 x Home Runs. |\n",
    "| GDP | Double Plays Grounded Into. Only includes standard 6-4-3, 4-3, etc. double plays. First tracked in 1933. For gamelogs only in seasons we have play-by-play, we include triple plays as well. All official seasonal totals do not include GITP's. |\n",
    "| HBP | Times Hit by a Pitch |\n",
    "| SH | Sacrifice Hits (Sacrifice Bunts) |\n",
    "|SF | Sacrifice Flies. First tracked in 1954. |\n",
    "| IBB | Intentional Bases on Balls. First tracked in 1955. |\n",
    "|LOB | Runners Left On Base |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c290c73e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Learning Goals\n",
    "\n",
    "\n",
    "- Use Pandas for importing data from CSV and Excel Files\n",
    "- Creation your own Dataframe using Python Dictionaries\n",
    "- Data selection of rows and columns with loc and iloc\n",
    "- Data Filtering with conditionals\n",
    "- How to calculate key statisitics \n",
    "- Handling null data \n",
    "- Changing data types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a207659",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Introduction:\n",
    "\n",
    "This SCORE module will be a introduction to the basics of the Pandas Library in Python. We will go over some of the basic items need to use Python and Pandas throughout this module. \n",
    "\n",
    "Some of the Topics we will be discussing: \n",
    "\n",
    "    - Reading and Importing Data\n",
    "\n",
    "    - Creating a Dataframe\n",
    "\n",
    "    - Creating a Series \n",
    "\n",
    "    - Data Selection\n",
    "\n",
    "    - Dataframe Analysis\n",
    "\n",
    "    - Data Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cbae96",
   "metadata": {},
   "source": [
    "# Importing Pandas:\n",
    "\n",
    "Before getting started, we need to import the Pandas Library into this Jupytr Notebook. \n",
    "\n",
    "Try Running the following code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fe64017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Pandas library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3f7f5f",
   "metadata": {},
   "source": [
    "NOTE: \"as pd\" is an alias we can use for Pandas so that we do not have to type out Pandas everytime we want to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd74a29",
   "metadata": {},
   "source": [
    "If that code did not run, you may need to download Pandas onto your Computer. This can be done by running the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5faa575f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2045187497.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mpip install pandas\u001b[39m\n        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Download Pandas library\n",
    "pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bb721c",
   "metadata": {},
   "source": [
    "# Importing / Reading In Data:\n",
    "\n",
    "Importing data into Python allows us to turn raw numbers into powerful insights with a few lines of Python. Learning to read data into Python isn’t just a skill; it’s the key to becoming a data scientist or a data analyst.\n",
    "\n",
    "We can read in several different file types using the Pandas library. This can include CSV files, Excel files (XLSX), HTML files, JSON files, etc. Doing this will automatically read in the data as a dataframe which is essentially the Python version of an Excel spreadsheet for organizing data. We wil talk about this later on in the module.\n",
    "\n",
    "We will keep it simple by importing the same dataset in CSV form and Excel Form. \n",
    "\n",
    "Lets go ahead and run a few of the code items below so that we can read in some of our Football datasets for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7413c67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Baseball Data CSV file as a DataFrame\n",
    "CSV_Batting_Data_2024 = pd.read_csv('https://raw.githubusercontent.com/ahaze65/Data-For-Pandas-Module/refs/heads/main/2024_MLB_Team_Batting_Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259d52cc",
   "metadata": {},
   "source": [
    "In order to Read an Excel file in Python you may need to download \"openpyxl\". \n",
    "\n",
    "This can be done by running the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bfa76e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449487d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Baseball Data Excel file as a DataFrame\n",
    "EXCEL_Batting_Data_2024 = pd.read_excel('https://raw.githubusercontent.com/ahaze65/Data-For-Pandas-Module/main/2024_MLB_Team_Batting_Data_Excel_Version.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd4782e",
   "metadata": {},
   "source": [
    "If we wanted to import data and automatically replace any null values with a value of our choosing, we need to add on an extra argument in our read statement. We may want to do this because it becomes easier to locate null values. Without doing this step, null values will just show up as blanks and cause problems down the road. In a bigger dataset, it may become easier to find null values after implementing this step and using a function to find them by the value entered. \n",
    "\n",
    "Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdaa5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXCEL_Batting_Data_2024_NA_version = pd.read_excel('https://raw.githubusercontent.com/ahaze65/Data-For-Pandas-Module/main/2024_MLB_Team_Batting_Data_Excel_Version.xlsx', na_values=['NA'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f391363b",
   "metadata": {},
   "source": [
    "# Dataframes and Basic Data Selection:\n",
    "\n",
    "As discussed earlier, Dataframes are a convenient way of organizing data in python using pandas. Dataframes are a lot like an excel spreadsheet; it is a way of organizing data into rows and columns with Python. Each column can hold different data types and the size of the dataframe is mutable through the removal of rows and columns. Dataframes are essential to python and allow you to do many different thing to the data including data cleaning, adding/deleting columns and rows, data entry, data manipulation, etc. \n",
    "\n",
    "Lets take a look at how to create our own dataframe. \n",
    "\n",
    "Run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ade74f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        State      Capital\n",
      "0     Alabama   Montgomery\n",
      "1      Alaska       Juneau\n",
      "2     Arizona      Phoenix\n",
      "3    Arkansas  Little Rock\n",
      "4  California   Sacramento\n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame called df that stores information about States and their capitals\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "    'State': ['Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California'],\n",
    "    'Capital': ['Montgomery', 'Juneau', 'Phoenix', 'Little Rock', 'Sacramento']\n",
    "    }\n",
    ")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a42706",
   "metadata": {},
   "source": [
    "There are a few functions we can use to gather data from only specific columns and/or rows:\n",
    "\n",
    " - loc[ ]: Accesses rows and columns by labels.\n",
    " - iloc[ ]: Accesses rows and columns by integer-based index.\n",
    " - df_name['column_name']: Selects a specific column.\n",
    " - df_name[['column_name1', 'column_name2']]: Selects multiple columns.\n",
    "\n",
    "\n",
    "\n",
    "Now Lets try printing out a specific row number and column from the dataframe we just made."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db27bc42",
   "metadata": {},
   "source": [
    "NOTE: Columns and rows in dataframes use 0-based indexing.\n",
    "\n",
    "This Means that the first item in a Python list start with the index 0 and not 1. For example, if I want to get the very first item in a list I would do this: list[0]. \n",
    "\n",
    "Here is code example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdff3550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list = [1,2,3,4,5,6,7,8,9,10]\n",
    "list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a027e3",
   "metadata": {},
   "source": [
    "### Loc[ ]:\n",
    "\n",
    "Syntax: df.loc[start_row (inclusive): end_row (exclusive)].\n",
    "\n",
    " - If you want to print all rows from the second row to the end, you can use df.loc['row_1':]. \n",
    "\n",
    " - If you want to print up to but not including the second row, you can use df.loc[:row_1].\n",
    "\n",
    "Loc[ ] uses labels to locate rows and columns but currently our rows currently use integer-based indexing. This means that our rows cannot be identified by labels. Let's Change that. \n",
    "\n",
    "Run the code below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c88940cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         State      Capital\n",
      "row3   Arizona      Phoenix\n",
      "row4  Arkansas  Little Rock\n"
     ]
    }
   ],
   "source": [
    "# Create a copy our df\n",
    "df_copy = df\n",
    "\n",
    "# Add row labels to our DataFrame\n",
    "df.index = ['row0', 'row1', 'row3', 'row4', 'row5']\n",
    "\n",
    "# Lets try printing the DataFrame with .loc[]\n",
    "\n",
    "print(df.loc['row2':'row4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f198e968",
   "metadata": {},
   "source": [
    "We can also apply filtering to our row level operations. For example, lets filter and get the rows where the capital is Little Rock.  Note that we have to use `==` to specify the truth of our equality and to distinguish from `=` which assigns values to an object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b352f282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         State      Capital\n",
      "row4  Arkansas  Little Rock\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[df['Capital'] == 'Little Rock'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4e6955",
   "metadata": {},
   "source": [
    "We can also do the reverse and return any rows whose capital is NOT Little Rock.  Note that we use `!=` for 'not equal to.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea514466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           State     Capital\n",
      "row0     Alabama  Montgomery\n",
      "row1      Alaska      Juneau\n",
      "row3     Arizona     Phoenix\n",
      "row5  California  Sacramento\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[df['Capital'] != 'Little Rock'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2298a03",
   "metadata": {},
   "source": [
    "### iLoc[ ]:\n",
    "\n",
    "Syntax: df.iloc[start_row (inclusive): end_row (exclusive)].\n",
    "\n",
    " - If you want to print all rows from the second row to the end, you can use df.loc[1:]. \n",
    "\n",
    " - If you want to print up to but not including the second row, you can use df.loc[:1].\n",
    "\n",
    "Unlike loc[], we can use the standard integer-based index. We can use either our copy of the dataframe with String labeled indexing or our original dataframe with integer-based indexing. \n",
    "\n",
    "Run the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f785c819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the first 3 rows of the DataFrame\n",
    "print(df.iloc[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f9b953",
   "metadata": {},
   "source": [
    "Notice how iloc still works despite the string label indexing? Very convenient to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30eb71e",
   "metadata": {},
   "source": [
    "### df_name['column_name'] and df_name[['column_name1', 'column_name2']]:\n",
    "\n",
    "Luckily, columns are a bit easier to work with whether you are using 1 or many. The only 2 differences between the two are the usage of one bracket vs double brackets and comma seperated column entry.\n",
    "\n",
    "Lets try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b987968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the state names only\n",
    "print(df['State'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e346b762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's print out the state and capital names\n",
    "print(df[['State', 'Capital']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe1cb8b",
   "metadata": {},
   "source": [
    "# Dataframe Analysis:\n",
    "\n",
    "\n",
    "The Pandas library gives us quite a few functions to gather information about a dataframe. \n",
    "\n",
    "Functions we will be learning about:\n",
    " - .head(): Displays the first n rows of a DataFrame.\n",
    " - .tail(): Displays the last n rows of a DataFrame.\n",
    " - .info(): Provides information about the DataFrame, including data types and non-null counts.\n",
    " - .describe(): Generates descriptive statistics of numerical columns.\n",
    " - .shape: Returns the dimensions of the DataFrame (rows, columns).\n",
    "\n",
    "\n",
    "Let's use our Baseball dataset for this one!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2975a0",
   "metadata": {},
   "source": [
    "## .head()\n",
    "\n",
    "By deafult, .head() will show us the first 5 rows of a dataframe. However, we can specify how many rows we want if needed.\n",
    "\n",
    "Run the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64759c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the first 5 rows of the Dataframe\n",
    "CSV_Batting_Data_2024.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f50746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out only the first 2 rows of the Dataframe\n",
    "CSV_Batting_Data_2024.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4247739",
   "metadata": {},
   "source": [
    "## .tail()\n",
    "\n",
    "Just like .head(), .tail() will show us 5 rows by default but it shows us the last 5 rows of a dataframe instead. We can also specify how many rows we want if needed.\n",
    "\n",
    "Run the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0147d204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the last 5 rows of the Dataframe\n",
    "CSV_Batting_Data_2024.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd91cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the last 2 rows of the Dataframe\n",
    "\n",
    "CSV_Batting_Data_2024.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cbdb81",
   "metadata": {},
   "source": [
    "NOTE: As you can see, there is a leagure average and a 'NaN' row at the bottom. There represent a total sum row and an average row. However, we may not want these in our data since we only want teams as our rows. We will go over how to get rid of these later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4648e6",
   "metadata": {},
   "source": [
    "## .info()\n",
    "\n",
    ".info() will give you some brief information about a dataset. This will include column names, column data types (strings, integers, floats, etc.), how many rows of non-null data are in each column, and memory usage. \n",
    "\n",
    "Run the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb4e351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets get some information about our baseball data!\n",
    "CSV_Batting_Data_2024.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71fd75f",
   "metadata": {},
   "source": [
    "## .describe()\n",
    "\n",
    ".describe() will give you some basic summary statisitics of each column including standard deviation, average, count of rows, the maximum value, the minimum value and percentiles. \n",
    "\n",
    "Run the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f72782",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_Batting_Data_2024.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eee8b62",
   "metadata": {},
   "source": [
    "## .shape\n",
    "\n",
    "\n",
    ".shape is a very simple function that returns how many rows and columns are in the dataframe. It's output states rows first then columns second (r, c)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7968ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check how many columns and rows are in the basbeball dataset.\n",
    "CSV_Batting_Data_2024.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd55c68b",
   "metadata": {},
   "source": [
    "There are 32 rows and 29 columns in total!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bad6910",
   "metadata": {},
   "source": [
    "# Data Manipulation using Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16f4ed4",
   "metadata": {},
   "source": [
    "There are a lot of different functions that you can use for data manipulation with Pandas. In this module we will go over the following:\n",
    "\n",
    "- .drop()\n",
    "- .dropna()\n",
    "- .fillna()\n",
    "- .astype()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e48bcb5",
   "metadata": {},
   "source": [
    "## .drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd1fd50",
   "metadata": {},
   "source": [
    ".drop() is a very simple function that can drop given rows/columns in a dataframe. Lets use our Baseball dataset from earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed1e854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check the column names in the baseball dataset.\n",
    "CSV_Batting_Data_2024.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c06cdc0",
   "metadata": {},
   "source": [
    "Lets say that we don't care about the average age of batters. So lets create a copy of the dataset and get rid of that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a80c247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the dataset.\n",
    "copy_dataset = CSV_Batting_Data_2024.copy()\n",
    "\n",
    "# Lets get rid of the average batters age column 'BatAge'\n",
    "copy_dataset.drop(columns=['BatAge'],inplace=True)\n",
    "copy_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53d6b16",
   "metadata": {},
   "source": [
    "we use 'inplace = true' because it allows us to apply our changes to the original dataset instead of creating a temporary copy of the datset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d889f55c",
   "metadata": {},
   "source": [
    "We can also drop rows and use conditions for .drop()\n",
    "\n",
    "Run the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c959a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_dataset.drop(0, inplace=True)\n",
    "\n",
    "copy_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facff8f7",
   "metadata": {},
   "source": [
    "See how it got rid of the Arizona Diamondbacks data using row indexing?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ba730a",
   "metadata": {},
   "source": [
    "Now that we have learned about .drop(), lets drop the last 2 rows of the dataset() because they are not teams. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb29de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_Batting_Data_2024.drop([30,31], inplace=True)\n",
    "CSV_Batting_Data_2024.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f029a81d",
   "metadata": {},
   "source": [
    "## .dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daed72ac",
   "metadata": {},
   "source": [
    ".dropna() is a very simple function that allows you to remove all rows with null values.\n",
    "\n",
    "Let's start by creating our own dataframe for this example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17efad1a",
   "metadata": {},
   "source": [
    "We are going to want to import Numpy in order to make null data entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bef8358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ad4336",
   "metadata": {},
   "source": [
    "Do a pip install like earlier if you need to download it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70180a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      State      Capital\n",
      "0   Alabama   Montgomery\n",
      "1    Alaska          NaN\n",
      "2   Arizona      Phoenix\n",
      "3  Arkansas  Little Rock\n",
      "4       NaN   Sacramento\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df1 = pd.DataFrame(\n",
    "    {\n",
    "    'State': ['Alabama', 'Alaska', 'Arizona', 'Arkansas', np.nan],\n",
    "    'Capital': ['Montgomery', np.nan, 'Phoenix', 'Little Rock', 'Sacramento']\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc6e088",
   "metadata": {},
   "source": [
    "Now lets get rid of those null values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40462233",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dropna(inplace=True)\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dac55e",
   "metadata": {},
   "source": [
    "See how it dropped those rows! Very useful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e9d216",
   "metadata": {},
   "source": [
    "## .fillna()\n",
    "\n",
    "This function is used to fill null values with a value of your choice.\n",
    "\n",
    "Lets use the custom df we used earlier as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520e846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(\n",
    "    {\n",
    "    'State': ['Alabama', 'Alaska', 'Arizona', 'Arkansas', np.nan],\n",
    "    'Capital': ['Montgomery', np.nan, 'Phoenix', 'Little Rock', 'Sacramento']\n",
    "    }\n",
    ")\n",
    "\n",
    "# Lets fill those missing values with 'empty!'\n",
    "df1.fillna('empty!', inplace=True)\n",
    "\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3b7810",
   "metadata": {},
   "source": [
    "# .astype()\n",
    "\n",
    "\n",
    "This function declares a pandas object as a certain data type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82d1100",
   "metadata": {},
   "source": [
    "Let's create a custom example with some players and enter their batting averages as strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "398284bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Player           3 non-null      object\n",
      " 1   Team             3 non-null      object\n",
      " 2   Batting_Average  3 non-null      object\n",
      " 3   Home_Runs        3 non-null      int64 \n",
      " 4   RBIs             3 non-null      int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 252.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Lets create a new DataFrame with some batting numbers\n",
    "batting_numbers = pd.DataFrame(\n",
    "    {\n",
    "        'Player': ['Bryce Harper', 'Andrew McCutchen', 'Buster Posey'],\n",
    "        'Team': ['Philadelphia Phillies', 'Pittsburgh Pirates', 'San Francisco Giants'],\n",
    "        'Batting_Average': ['0.300', '0.275', '0.290'],\n",
    "        'Home_Runs': [30, 25, 20],\n",
    "        'RBIs': [90, 80, 70]\n",
    "    }\n",
    ")\n",
    "\n",
    "# Let's check the column type\n",
    "print(batting_numbers.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d73d1e3",
   "metadata": {},
   "source": [
    "Notice how 'Batting_Average' is an object dtype? lets change that to be a float so they are in a decimal format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80536456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Player           3 non-null      object \n",
      " 1   Team             3 non-null      object \n",
      " 2   Batting_Average  3 non-null      float64\n",
      " 3   Home_Runs        3 non-null      int64  \n",
      " 4   RBIs             3 non-null      int64  \n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 252.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "batting_numbers['Batting_Average'] = batting_numbers['Batting_Average'].astype(float)\n",
    "# Let's check the column type again \n",
    "print(batting_numbers.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c28cc71",
   "metadata": {},
   "source": [
    "Perfect!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab9d1a8",
   "metadata": {},
   "source": [
    "# Computing Basic Statistics\n",
    "\n",
    "\n",
    "Instead of using .describe() on a whole dataframe as perviously discussed, we can just calculate some basic statisitics of one column such as:\n",
    "\n",
    " - .mean()\n",
    " - .median()\n",
    " - .mode()\n",
    " - .max()\n",
    " - .min()\n",
    " - .std()\n",
    "\n",
    "I'll provide some examples below for the column 'SO' which will allow us to examine some strikeout statisitics among all MLB teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dbba1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Mean: {CSV_Batting_Data_2024['SO'].mean()}')\n",
    "\n",
    "print(f'Median: {CSV_Batting_Data_2024['SO'].median()}')\n",
    "\n",
    "print(f'Mode: {CSV_Batting_Data_2024[\"SO\"].mode()}')\n",
    "\n",
    "print(f'Maximum: {CSV_Batting_Data_2024[\"SO\"].max()}')\n",
    "\n",
    "print(f'Minimum: {CSV_Batting_Data_2024[\"SO\"].min()}')\n",
    "\n",
    "print(f'Standard Deviation: {CSV_Batting_Data_2024[\"SO\"].std()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128346a5",
   "metadata": {},
   "source": [
    "We can see that the league average for team strikeouts last season was 1373.2333!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0219089",
   "metadata": {},
   "source": [
    "# Numpy Conversion\n",
    "\n",
    "\n",
    "\n",
    "Lastly, lets go over how to convert a dataframe column to a numpy array for easier calculations.\n",
    "\n",
    "\n",
    "Lets start by recreating our custom dataframe from earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46cd80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batting_numbers2 = pd.DataFrame(\n",
    "    {\n",
    "        'Player': ['Bryce Harper', 'Andrew McCutchen', 'Buster Posey'],\n",
    "        'Team': ['Philadelphia Phillies', 'Pittsburgh Pirates', 'San Francisco Giants'],\n",
    "        'Batting_Average': [0.300, 0.275, 0.290],\n",
    "        'Home_Runs': [30, 25, 20],\n",
    "        'RBIs': [90, 80, 70]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c519ac0f",
   "metadata": {},
   "source": [
    "Lets say we want to convert the 'Home_Runs' column to a numpy array. So we will do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff527d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "HR_array = batting_numbers2['Home_Runs'].to_numpy()\n",
    "print(HR_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc47d249",
   "metadata": {},
   "source": [
    "# Review Questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24f2314",
   "metadata": {},
   "source": [
    "Answer the following questions about Pandas for review:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27de5e11",
   "metadata": {},
   "source": [
    "## For Questions 1 - 3 use the following dataset: https://raw.githubusercontent.com/ahaze65/Data-For-Pandas-Module/refs/heads/main/Pitching%20Data%20-%20MLB%202024%20Team%20Stats.csv\n",
    "\n",
    "\n",
    "SOURCE:\n",
    "\n",
    "This dataset is from Baseball Reference. Please go visit their website at https://www.baseball-reference.com\n",
    "\n",
    "Or for this exact dataset: https://www.baseball-reference.com/leagues/majors/2024.shtml#all_teams_standard_pitching "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f33dfa3",
   "metadata": {},
   "source": [
    "### 1. Import the dataset from above, drop the last 2 rows and find the mean amount of earned runs allowed last year. \n",
    "\n",
    "Hint: Earned Runs Allowed column name is 'ER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9baec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b143569",
   "metadata": {},
   "source": [
    "### 2. Assign String indexes to every row that matches the team of that row. Test this by using a certain function that allows you to view rows by labeling\n",
    "\n",
    "Hint: Reuse the team name column 'Tm'\n",
    "\n",
    "Hint: This function is in the data selection section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d038cf6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d049d8a0",
   "metadata": {},
   "source": [
    "### 3. Print out a list of teams who had at least 1 complete pitching shutout last season. \n",
    "\n",
    "Hint: complete shutout column is called 'cSho'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc53136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf3c7a9c",
   "metadata": {},
   "source": [
    "### 4. Create your own dataframe with at least 10 rows and 3 columns. Include at least 3 rows with null data points (Use np.nan) and make at least 1 column of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cf7e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c402585b",
   "metadata": {},
   "source": [
    "### 5. Using the dataframe you created in the last question, fill those null values with a phrase of your choosing and print out the dataframe. Make sure you are NOT applying those changes to the original dataframe.\n",
    "\n",
    "Hint: do not use the inplace argument in you function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8554e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2f820b6",
   "metadata": {},
   "source": [
    "### 6. Still using that dataframe you created, drop any rows that conatain null values. Make sure you apply those changes to your dataframe and NOT to a temporary copy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d06bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73344082",
   "metadata": {},
   "source": [
    "### 7. Using one function, calculate all key statisitics for your dataframe such as mean, median, min, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d4eef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64e20ba0",
   "metadata": {},
   "source": [
    "### 8. View the last 5 rows of your dataframe and drop 3 of them of your choosing with only one line of code. View the last 5 rows again to check your changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aff91c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1de2ff1c",
   "metadata": {},
   "source": [
    "### 9. Choose one of your numeric columns, convert it to an integer data type (if it is not already) and then into a Numpy array. Print the final array out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73feb578",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
